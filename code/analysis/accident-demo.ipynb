{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Things to do:\n",
    "1. use multiple frames to predict next frame.\n",
    "2. Test different sample frequencies.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import sys\n",
    "# you might want to run this if you don't have ffmpeg installed\n",
    "# imageio.plugins.ffmpeg.download()\n",
    "\n",
    "context = {}\n",
    "context['home'] = os.getcwd()\n",
    "context['fname_input'] = 'test.mp4'\n",
    "# current analysis must be done with 2.0 or 5.0 fps\n",
    "context['frate'] = 2.0\n",
    "assert context['frate'] in (2.0, 5.0)\n",
    "\n",
    "\n",
    "def read_video(fname_input, frate=2.0):\n",
    "    global context\n",
    "    home = context['home']\n",
    "    fname_full = os.path.join(home, fname_input)\n",
    "    vid = imageio.get_reader(fname_full, 'ffmpeg')\n",
    "    vid_info = vid.get_meta_data()\n",
    "    \n",
    "    context['s_hz'] = vid_info['fps']\n",
    "    s_length = vid_info['duration']\n",
    "    context['s_length'] = s_length\n",
    "\n",
    "    min_duration = 1.0 / frate\n",
    "    if s_length < min_duration:\n",
    "        msg = 'The length of this video ({0}s) is smaller than the minimum duration ({1}s).'\\\n",
    "            .format(s_length, min_duration)\n",
    "        raise ValueError(msg)\n",
    "    else:\n",
    "        return vid\n",
    "\n",
    "vid = read_video(context['fname_input'], context['frate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data has 1 part(s), starts at image 0 and ends at image 210.\n"
     ]
    }
   ],
   "source": [
    "# This takes the frames of the avi and converts them into the .hkl files\n",
    "# The script is based on process_kitti\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import hickle as hkl\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_im(im, desired_sz):\n",
    "    '''\n",
    "    resize and crop image\n",
    "    params: im - an image represented in a 5d array\n",
    "            desired_sz - a tuple of width and height\n",
    "    returns: a transformed image\n",
    "    '''\n",
    "    target_ds = float(desired_sz[0])/im.shape[0]\n",
    "    im = imresize(im, (desired_sz[0], int(np.round(target_ds * im.shape[1]))))\n",
    "    d = (im.shape[1] - desired_sz[1]) / 2\n",
    "    im = im[:, d:d + desired_sz[1]]\n",
    "    return im\n",
    "\n",
    "\n",
    "def convert_video_to_hkl(vid, fname_input, desired_im_sz=(128, 160)):\n",
    "    \n",
    "    # set the params\n",
    "    global context\n",
    "    frate = context['frate']\n",
    "    s_hz = context['s_hz']\n",
    "    s_length = context['s_length']\n",
    "    \n",
    "    frames_per_clip = 10\n",
    "    context['frames_per_clip'] = frames_per_clip\n",
    "    max_clip = 1000 # limit of clips for a part\n",
    "    split = 'test'\n",
    "\n",
    "    # step_im\n",
    "    s_num_frames = int(round(s_hz * s_length))\n",
    "    s_orig_ms_per_frame = 1000 / s_hz\n",
    "    s_targ_ms_per_frame = 1000.0 / frate\n",
    "    context['s_orig_ms_per_frame'] = s_orig_ms_per_frame\n",
    "\n",
    "    # skip: step of the sampling method\n",
    "    skip = round(s_targ_ms_per_frame / s_orig_ms_per_frame)\n",
    "    context['skip'] = skip\n",
    "\n",
    "    s_actual_hz = s_hz / skip\n",
    "    s_actual_ms_per_frame = 1000 / s_actual_hz\n",
    "    s_total_clips = int(s_num_frames / (frames_per_clip * skip))\n",
    "\n",
    "    # parts: each part contains no more than <max_clip> number of clips\n",
    "    parts = int(s_total_clips / max_clip) + 1\n",
    "    context['parts'] = parts\n",
    "    step_im = max_clip * frames_per_clip\n",
    "    suffix = '_P' + str(parts) + '_'\n",
    "    context['suffix'] = suffix\n",
    "\n",
    "    # num_im: total number of images sampled\n",
    "    num_im = s_total_clips * frames_per_clip \n",
    "\n",
    "    # initialize the test data\n",
    "    X = np.zeros((num_im,) + desired_im_sz + (3,), np.uint8)\n",
    "    # source in each frame makes sure each clip has frames in the same video\n",
    "    source_list = [fname_input] * num_im\n",
    "\n",
    "    # sample the images from vid\n",
    "    ct = 0\n",
    "    for i, im_out in enumerate(vid):\n",
    "        if i % skip == 0:\n",
    "            im = vid.get_data(i)\n",
    "            X[ct] = process_im(im, desired_im_sz)\n",
    "            ct = ct + 1\n",
    "            if ct == num_im:\n",
    "                break\n",
    "\n",
    "    # store the images and sources into repective hickle file\n",
    "    home = context['home']\n",
    "    if not (os.path.isdir(home + \"/test_avi\")):\n",
    "        os.mkdir(home + '/test_avi')\n",
    "    else:\n",
    "        allfiles =os.listdir(home + '/test_avi')\n",
    "        for temp in allfiles:\n",
    "            os.remove(home + '/test_avi' + '/' + temp)\n",
    "        os.rmdir(home + '/test_avi')\n",
    "        os.mkdir(home + '/test_avi')\n",
    "\n",
    "    for part in range(1,parts+1):\n",
    "        xbeg = int((part - 1) * step_im)\n",
    "        if (part == parts):\n",
    "            xend = num_im    \n",
    "        else:\n",
    "            xend = int(part * step_im) \n",
    "        print 'Test data has {0} part(s), starts at image {1} and ends at image {2}.'.format(part,xbeg,xend)\n",
    "        hkl.dump(X[xbeg:xend], os.path.join(home, 'test_avi', 'X_' + split + suffix+ str(part)+'.hkl'))\n",
    "        hkl.dump(source_list[xbeg:xend], os.path.join(home, 'test_avi', 'sources_' + split + suffix + str(part)+ '.hkl'))\n",
    "    \n",
    "\n",
    "convert_video_to_hkl(vid, context['fname_input'], desired_im_sz=(128, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Evaluate trained PredNet on test video.\n",
    "Calculates mean-squared error\n",
    "'''\n",
    "\n",
    "from six.moves import cPickle\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "\n",
    "PREDNET_PATH = '../models/prednet'\n",
    "sys.path.append(PREDNET_PATH)\n",
    "from prednet import PredNet\n",
    "from data_utils import SequenceGenerator\n",
    "\n",
    "DATA_DIR = './test_avi/'\n",
    "WEIGHTS_DIR = os.path.join(PREDNET_PATH, 'model_data')\n",
    "RESULTS_DIR = './test_results_avi/'\n",
    "\n",
    "# these are set in the cell above, uncomment this and this cell should\n",
    "# work for avi's less than 1000 frames (1000 clips at 10 frames/clip)\n",
    "# This would be 500 sec at 2Hz or 200 sec at 5Hz \n",
    "# parts = 1\n",
    "# suffix = '_P1_'\n",
    "\n",
    "def assemble_model():\n",
    "\n",
    "    global context\n",
    "    batch_size = 10\n",
    "    context['batch_size'] = batch_size\n",
    "    nt = 10  # number of frames per clip\n",
    "    context['nt'] = nt\n",
    "    # prednet used KITTI dataset that has 10 frames per clip, which is changable\n",
    "\n",
    "    fpath_weights = os.path.join(WEIGHTS_DIR, 'prednet_kitti_weights.hdf5')\n",
    "    fpath_json = os.path.join(WEIGHTS_DIR, 'prednet_kitti_model.json')\n",
    "\n",
    "    # Load trained model\n",
    "    with open(fpath_json, 'r') as fj:\n",
    "        json_string = fj.read()\n",
    "    trained_model = model_from_json(json_string, custom_objects = {'PredNet': PredNet})\n",
    "    trained_model.load_weights(fpath_weights)\n",
    "\n",
    "    # get configs from the trained model\n",
    "    layer_config = trained_model.layers[1].get_config()\n",
    "    layer_config['output_mode'] = 'prediction'\n",
    "    dim_ordering = layer_config['dim_ordering']\n",
    "    context['dim_ordering'] = dim_ordering\n",
    "\n",
    "    # assemble test model (to output predictions) \n",
    "    '''what does this means? only using one layer'''\n",
    "    test_prednet = PredNet(weights=trained_model.layers[1].get_weights(), **layer_config)\n",
    "    input_shape = list(trained_model.layers[0].batch_input_shape[1:])\n",
    "    input_shape[0] = nt\n",
    "    inputs = Input(shape=tuple(input_shape))\n",
    "    predictions = test_prednet(inputs)\n",
    "    test_model = Model(input=inputs, output=predictions)\n",
    "    \n",
    "    return test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_and_evaluate(test_model):\n",
    "    global context\n",
    "    batch_size = context['batch_size']\n",
    "    nt = context['nt']\n",
    "    dim_ordering = context['dim_ordering']\n",
    "    \n",
    "    if not os.path.exists(RESULTS_DIR): \n",
    "        os.mkdir(RESULTS_DIR)\n",
    "\n",
    "    parts = context['parts']\n",
    "    for part in range(1, parts+1):\n",
    "        suffix = context['suffix']\n",
    "        curr_test = 'X_test' + suffix + str(part) + '.hkl'\n",
    "        curr_sources = 'sources_test' + suffix + str(part) + '.hkl'\n",
    "        test_file = os.path.join(DATA_DIR, curr_test)\n",
    "        test_sources = os.path.join(DATA_DIR, curr_sources)\n",
    "\n",
    "        # generate inputs from the test hickle file\n",
    "        test_generator = SequenceGenerator(test_file, test_sources, nt,\\\n",
    "                                           sequence_start_mode='unique', dim_ordering=dim_ordering)\n",
    "\n",
    "        # final X_test.shape = (26, 10, 128, 160, 3)\n",
    "        X_test = test_generator.create_all()\n",
    "        X_hat = test_model.predict(X_test, batch_size)\n",
    "        if dim_ordering == 'th':\n",
    "            X_test = np.transpose(X_test, (0, 1, 3, 4, 2))\n",
    "            X_hat = np.transpose(X_hat, (0, 1, 3, 4, 2))\n",
    "\n",
    "        curr_mse_frame2 = 'mse_frame2' + suffix + str(part) + '.csv'\n",
    "        mse_frame2_out = os.path.join(RESULTS_DIR, curr_mse_frame2)\n",
    "\n",
    "        # [2, 3, 4] is the x, y, grb\n",
    "        mse_point = (X_test - X_hat) ** 2\n",
    "        mse_point[:, :2] = 0  # the errors of first two frames not helpful\n",
    "        mse_frame2 = np.squeeze(np.apply_over_axes(np.mean, mse_point, [2,3,4]))\n",
    "        np.savetxt(mse_frame2_out, mse_frame2, delimiter=\",\")\n",
    "\n",
    "        print 'mse_frame2'\n",
    "        print type(mse_frame2)\n",
    "        print mse_frame2.shape\n",
    "        print 'Errors in the first clip:'\n",
    "        print mse_frame2[0, :]\n",
    "\n",
    "    return mse_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_frame2\n",
      "<type 'numpy.ndarray'>\n",
      "(21, 10)\n",
      "Errors in the first clip:\n",
      "[ 0.          0.          0.00084366  0.00073687  0.00047403  0.00061762\n",
      "  0.00046855  0.00054966  0.00029485  0.00048491]\n"
     ]
    }
   ],
   "source": [
    "# get the squared error for each frame\n",
    "test_model = assemble_model()\n",
    "mse_frame2 = predict_and_evaluate(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using threshold: 0.00121029856382.\n",
      "An accident happened from 32.0s to 34.0s.\n",
      "An accident happened from 35.0s to 39.5s.\n",
      "An accident happened from 46.0s to 47.0s.\n",
      "An accident happened from 87.5s to 88.5s.\n"
     ]
    }
   ],
   "source": [
    "def get_accidents(mse_frame2):\n",
    "    '''\n",
    "    '''\n",
    "    global context\n",
    "    frate = context['frate']\n",
    "    frames_per_clip = context['frames_per_clip']\n",
    "    skip = context['skip']\n",
    "    s_orig_ms_per_frame = context['s_orig_ms_per_frame']\n",
    "    \n",
    "    # take first five seconds to calculate threshold\n",
    "    sample = mse_frame2[:int(frate), 2:].reshape(1, -1)\n",
    "    mean = np.mean(sample)\n",
    "    stdev = np.std(sample) \n",
    "\n",
    "    accident_threshold = mean + 5 * stdev\n",
    "    print 'Using threshold: {}.'.format(accident_threshold)\n",
    "    \n",
    "    accident_frames = np.where(mse_frame2 > accident_threshold, True, False)\n",
    "    \n",
    "    # for i, clip in enumerate(accident_frames):\n",
    "    #     print i * 5, clip\n",
    "    \n",
    "    second_per_frame = 1 / frate\n",
    "    accidents = []\n",
    "    accident_in_last_clip = False\n",
    "    for i, frame_arr in enumerate(accident_frames):\n",
    "        if np.sum(frame_arr) > 2:\n",
    "            if accident_in_last_clip:\n",
    "                start = 0\n",
    "            else:\n",
    "                start = np.argmax(frame_arr)\n",
    "            end = len(frame_arr) - 1\n",
    "            while not frame_arr[end]:\n",
    "                end -= 1\n",
    "            accidents.append(((i * 10 + start) * second_per_frame,\n",
    "                              (i * 10 + end) * second_per_frame))\n",
    "            accident_in_last_clip = True\n",
    "        else:\n",
    "            accident_in_last_clip = False\n",
    "    \n",
    "    return accidents\n",
    "\n",
    "\n",
    "accidents = get_accidents(mse_frame2)\n",
    "for accident in accidents:\n",
    "    print \"An accident happened from {0}s to {1}s.\".format(accident[0], accident[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
