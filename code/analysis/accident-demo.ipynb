{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters to run demo, change these as needed\n",
    "\n",
    "frate = 2.0 # choose either 2.0 or 5.0\n",
    "fname_in = 'test2.avi'\n",
    "\n",
    "# Current analysis must be done with 2.0 or 5.0 fps\n",
    "assert frate in (2.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this reads in the avi\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import sys\n",
    "# you might to run this if you don't have ffmpeg.exe\n",
    "# imageio.plugins.ffmpeg.download()xf\n",
    "\n",
    "home = os.getcwd()\n",
    "fname_full = os.path.join(home, fname_in)\n",
    "vid = imageio.get_reader(fname_full, 'ffmpeg')\n",
    "vid_info = vid.get_meta_data()\n",
    "s_hz = vid_info['fps']\n",
    "s_length = vid_info['duration']\n",
    "\n",
    "min_duration = 1.0 / frate\n",
    "if s_length < min_duration:\n",
    "    msg = 'The length of this video ({0}s) is smaller than the minimum duration ({1}s).'\\\n",
    "        .format(s_length, min_duration)\n",
    "    raise ValueError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data has 1 part(s), starts at image 0 and ends at image 240.\n"
     ]
    }
   ],
   "source": [
    "# This takes the frames of the avi and converts them into the .hkl files\n",
    "# The script is based on process_kitti\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import hickle as hkl\n",
    "import pandas as pd\n",
    "\n",
    "desired_im_sz = (128, 160)\n",
    "\n",
    "\n",
    "def process_im(im, desired_sz):\n",
    "    '''\n",
    "    resize and crop image\n",
    "    params: im - an image represented in a 5d array\n",
    "            desired_sz - a tuple of width and height\n",
    "    returns: a transformed image\n",
    "    '''\n",
    "    target_ds = float(desired_sz[0])/im.shape[0]\n",
    "    im = imresize(im, (desired_sz[0], int(np.round(target_ds * im.shape[1]))))\n",
    "    d = (im.shape[1] - desired_sz[1]) / 2\n",
    "    im = im[:, d:d + desired_sz[1]]\n",
    "    return im\n",
    "\n",
    "split = 'test'\n",
    "frames_per_clip = 10\n",
    "max_clip = 1000 # a limit to the batch file size to run on my container\n",
    "\n",
    "# step_im\n",
    "s_num_frames = int(round(s_hz * s_length))\n",
    "s_orig_ms_per_frame = 1000 / s_hz\n",
    "s_targ_ms_per_frame = 1000.0 / frate\n",
    "\n",
    "# skip: step of the sampling method\n",
    "skip = round(s_targ_ms_per_frame / s_orig_ms_per_frame)\n",
    "\n",
    "s_actual_hz = s_hz / skip\n",
    "s_actual_ms_per_frame = 1000 / s_actual_hz\n",
    "s_total_clips = int(s_num_frames / (frames_per_clip * skip))\n",
    "\n",
    "# parts: each part contains no more than <max_clip> number of clips\n",
    "parts = int(s_total_clips / max_clip) + 1\n",
    "step_im = max_clip * frames_per_clip\n",
    "suffix = '_P' + str(parts) + '_'\n",
    "\n",
    "# num_im: total number of images sampled\n",
    "num_im = s_total_clips * frames_per_clip \n",
    "\n",
    "# initialize the test data\n",
    "X = np.zeros((num_im,) + desired_im_sz + (3,), np.uint8)\n",
    "# source in each frame makes sure each clip has frames in the same video\n",
    "source_list = [fname_in] * num_im\n",
    "\n",
    "# sample the images from vid\n",
    "ct = 0\n",
    "for i, im_out in enumerate(vid):\n",
    "    if i % skip == 0:\n",
    "        im = vid.get_data(i)\n",
    "        X[ct] = process_im(im, desired_im_sz)\n",
    "        ct = ct + 1\n",
    "        if ct == num_im:\n",
    "            break\n",
    "\n",
    "# store the images and sources into repective hickle file\n",
    "if not (os.path.isdir(home + \"/test_avi\")):\n",
    "    os.mkdir(home + '/test_avi')\n",
    "else:\n",
    "    allfiles =os.listdir(home + '/test_avi')\n",
    "    for temp in allfiles:\n",
    "        os.remove(home + '/test_avi' + '/' + temp)\n",
    "    os.rmdir(home + '/test_avi')\n",
    "    os.mkdir(home + '/test_avi')\n",
    "    \n",
    "for part in range(1,parts+1):\n",
    "    xbeg = int((part - 1) * step_im)\n",
    "    if (part == parts):\n",
    "        xend = num_im    \n",
    "    else:\n",
    "        xend = int(part * step_im) \n",
    "    print 'Test data has {0} part(s), starts at image {1} and ends at image {2}.'.format(part,xbeg,xend)\n",
    "    hkl.dump(X[xbeg:xend], os.path.join(home, 'test_avi', 'X_' + split + suffix+ str(part)+'.hkl'))\n",
    "    hkl.dump(source_list[xbeg:xend], os.path.join(home, 'test_avi', 'sources_' + split + suffix + str(part)+ '.hkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_frame2\n",
      "<type 'numpy.ndarray'>\n",
      "(24, 9)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Evaluate trained PredNet on test video.\n",
    "Calculates mean-squared error\n",
    "'''\n",
    "\n",
    "from six.moves import cPickle\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "\n",
    "PREDNET_PATH = '../models/prednet'\n",
    "sys.path.append(PREDNET_PATH)\n",
    "\n",
    "from prednet import PredNet\n",
    "from data_utils import SequenceGenerator\n",
    "\n",
    "DATA_DIR = './test_avi/'\n",
    "WEIGHTS_DIR = os.path.join(PREDNET_PATH, 'model_data')\n",
    "RESULTS_DIR = './test_results_avi/'\n",
    "\n",
    "# these are set in the cell above, uncomment this and this cell should\n",
    "# work for avi's less than 1000 frames (1000 clips at 10 frames/clip)\n",
    "# This would be 500 sec at 2Hz or 200 sec at 5Hz \n",
    "# parts = 1\n",
    "# suffix = '_P1_'\n",
    "\n",
    "batch_size = 10\n",
    "nt = 10  # number of frames per clip\n",
    "# prednet used KITTI dataset that has 10 frames per clip, which is changable\n",
    "\n",
    "fpath_weights = os.path.join(WEIGHTS_DIR, 'prednet_kitti_weights.hdf5')\n",
    "fpath_json = os.path.join(WEIGHTS_DIR, 'prednet_kitti_model.json')\n",
    "\n",
    "# Load trained model\n",
    "with open(fpath_json, 'r') as fj:\n",
    "    json_string = fj.read()\n",
    "trained_model = model_from_json(json_string, custom_objects = {'PredNet': PredNet})\n",
    "trained_model.load_weights(fpath_weights)\n",
    "\n",
    "# get configs from the trained model\n",
    "layer_config = trained_model.layers[1].get_config()\n",
    "layer_config['output_mode'] = 'prediction'\n",
    "dim_ordering = layer_config['dim_ordering']\n",
    "\n",
    "# assemble test model (to output predictions) \n",
    "'''what does this means? only using one layer'''\n",
    "test_prednet = PredNet(weights=trained_model.layers[1].get_weights(), **layer_config)\n",
    "input_shape = list(trained_model.layers[0].batch_input_shape[1:])\n",
    "input_shape[0] = nt\n",
    "inputs = Input(shape=tuple(input_shape))\n",
    "predictions = test_prednet(inputs)\n",
    "test_model = Model(input=inputs, output=predictions)\n",
    "\n",
    "if not os.path.exists(RESULTS_DIR): \n",
    "    os.mkdir(RESULTS_DIR)\n",
    "    \n",
    "f = open(RESULTS_DIR + 'prediction_scores.txt', 'w')\n",
    "\n",
    "for part in range(1, parts+1):\n",
    "\n",
    "    curr_test = 'X_test' + suffix + str(part) + '.hkl'\n",
    "    curr_sources = 'sources_test' + suffix + str(part) + '.hkl'\n",
    "    test_file = os.path.join(DATA_DIR, curr_test)\n",
    "    test_sources = os.path.join(DATA_DIR, curr_sources)\n",
    "\n",
    "    # generate inputs from the test hickle file\n",
    "    test_generator = SequenceGenerator(test_file, test_sources, nt,\\\n",
    "                                       sequence_start_mode='unique', dim_ordering=dim_ordering)\n",
    "    \n",
    "    # final X_test.shape = (26, 10, 128, 160, 3)\n",
    "    X_test = test_generator.create_all()\n",
    "    X_hat = test_model.predict(X_test, batch_size)\n",
    "    if dim_ordering == 'th':\n",
    "        X_test = np.transpose(X_test, (0, 1, 3, 4, 2))\n",
    "        X_hat = np.transpose(X_hat, (0, 1, 3, 4, 2))\n",
    "\n",
    "    curr_mse_frame2 = 'mse_frame2' + suffix + str(part) + '.csv'\n",
    "    mse_frame2_out = os.path.join(RESULTS_DIR, curr_mse_frame2)\n",
    "    \n",
    "    # [2, 3, 4] is the x, y, grb\n",
    "    mse_point = (X_test[:, 1:] - X_hat[:, 1:]) ** 2\n",
    "    mse_frame2 = np.squeeze(np.apply_over_axes(np.mean, mse_point, [2,3,4]))\n",
    "    np.savetxt(mse_frame2_out, mse_frame2, delimiter=\",\")\n",
    "\n",
    "    print 'mse_frame2'\n",
    "    print type(mse_frame2)\n",
    "    print mse_frame2.shape\n",
    "    \n",
    "    # Compare overall MSE's write results to prediction_scores.txt\n",
    "    mse_model = np.mean( (X_test[:, 1:] - X_hat[:, 1:])**2 )  # look at all timesteps except the first\n",
    "    mse_prev = np.mean( (X_test[:, :-1] - X_test[:, 1:])**2 )\n",
    "    mse_last = np.mean( (X_test[:, -1] - X_hat[:, -1])**2 )  # look only the last frame\n",
    "    f.write(\"part number: %d\\n\" % part)\n",
    "    f.write(\"Model MSE: %f\\n\" % mse_model)\n",
    "    f.write(\"Last Frame MSE: %f\" % mse_last)\n",
    "    f.write(\"Previous Frame MSE: %f\" % mse_prev)\n",
    "    \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessing possible accidents\n",
      "Possible accident in clip  1 starting time =  5005.00500501 ending time =  9509.50950951\n",
      "Possible accident in clip  3 starting time =  15015.015015 ending time =  19519.5195195\n",
      "Possible accident in clip  7 starting time =  35035.035035 ending time =  39539.5395395\n",
      "Possible accident in clip  8 starting time =  40040.04004 ending time =  44544.5445445\n",
      "Possible accident in clip  11 starting time =  55055.0550551 ending time =  59559.5595596\n",
      "Possible accident in clip  12 starting time =  60060.0600601 ending time =  64564.5645646\n",
      "Possible accident in clip  13 starting time =  65065.0650651 ending time =  69569.5695696\n",
      "Possible accident in clip  14 starting time =  70070.0700701 ending time =  74574.5745746\n",
      "Possible accident in clip  15 starting time =  75075.0750751 ending time =  79579.5795796\n",
      "Possible accident in clip  16 starting time =  80080.0800801 ending time =  84584.5845846\n",
      "Possible accident in clip  17 starting time =  85085.0850851 ending time =  89589.5895896\n",
      "Possible accident in clip  19 starting time =  95095.0950951 ending time =  99599.5995996\n",
      "Possible accident in clip  20 starting time =  100100.1001 ending time =  104604.604605\n",
      "Possible accident in clip  21 starting time =  105105.105105 ending time =  109609.60961\n"
     ]
    }
   ],
   "source": [
    "# see https://github.com/startupml/video/blob/master/results/README.md for rationale for these thresholds\n",
    "if frate == 2.0:\n",
    "    threshold = 0.00777565  # mse is away from 3 stdev\n",
    "else:\n",
    "    threshold = 0.004869763 \n",
    "    \n",
    "# overall mean of mse per clip, since mse of 2nd and 3rd frames are always higher \n",
    "mse_clip = pd.Series(np.squeeze(np.apply_over_axes(np.mean, mse_frame2, [1])))\n",
    "\n",
    "clip_size = mse_clip.shape[0]\n",
    "t_start = pd.Series(np.zeros(clip_size))\n",
    "t_end = pd.Series(np.zeros(clip_size))\n",
    "above_threshold = pd.Series(np.zeros(clip_size))\n",
    "\n",
    "for i in range(0, clip_size):\n",
    "    if mse_clip[i] >= threshold:\n",
    "        above_threshold[i] = 1\n",
    "    t_start[i] = i * (frames_per_clip * skip * s_orig_ms_per_frame)\n",
    "    t_end[i] = (i + 1) * (frames_per_clip * skip * s_orig_ms_per_frame) - (skip * s_orig_ms_per_frame)\n",
    "\n",
    "mse_clip_out = pd.concat([mse_clip,t_start,t_end,above_threshold],axis=1)\n",
    "mse_clip_out.columns = ['MSE_ave_over_clip','time_start','time_end','above_threshold']    \n",
    "mse_clip_out.to_csv(os.path.join(RESULTS_DIR, 'test_avi_mse_clip.csv'))  \n",
    "# the test video is 29.97HZ, making the duration of each clip not exactly 5s\n",
    "\n",
    "# if label the images by frame, should label before the mse arise\n",
    "\n",
    "print 'Assessing possible accidents'\n",
    "if (np.sum(mse_clip_out.above_threshold) == 0):\n",
    "    print \"No possible accidents found\"\n",
    "else:\n",
    "    for i in range(0,clip_size):\n",
    "        if (mse_clip_out.above_threshold.iloc[i] == 1):\n",
    "            print 'Possible accident in clip ',i, 'starting time = ', mse_clip_out.time_start.iloc[i], \\\n",
    "            'ending time = ',mse_clip_out.time_end.iloc[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
